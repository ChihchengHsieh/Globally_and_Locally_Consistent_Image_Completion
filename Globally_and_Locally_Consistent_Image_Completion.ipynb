{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#TODO: DataLoader\n",
    "#TODO: GANestimator\n",
    "\n",
    "\n",
    "class Parser():\n",
    "    #hyperparameters\n",
    "    def __init__(self):\n",
    "        #image setting\n",
    "        self.input_width=64\n",
    "        self.input_height=64\n",
    "        self.local_input_width=32\n",
    "        self.local_input_height=32\n",
    "        self.input_channel=3\n",
    "        self.input_dim=100\n",
    "        \n",
    "        #Training settings\n",
    "        self.continue_training=False\n",
    "        self.data='./'\n",
    "        self.batch_size=128\n",
    "        self.train_step=500000#400\n",
    "        self.Tc=90000\n",
    "        self.Td=10000\n",
    "        self.learning_rate=0.001\n",
    "        self.momentum=0.5\n",
    "        self.show_freq=20 # How many iteration will show a example\n",
    "        \n",
    "        #set alpha to 1 to give more weights to the discriminator loss\n",
    "        self.alpha=0.004\n",
    "        self.margin=5\n",
    "        self.img_path='./'\n",
    "        self.checkpoints_path='./checkpoint/'\n",
    "        self.graph_path='./graphs/'\n",
    "        self.images_path='./images/'\n",
    "\n",
    "def block_patch(input, margin=5):\n",
    "    shape = input.get_shape().as_list()\n",
    "    #create patch in random size\n",
    "    pad_size = tf.random_uniform([2], minval=15, maxval=25, dtype=tf.int32)\n",
    "    patch = tf.zeros([pad_size[0], pad_size[1], shape[-1]], dtype=tf.float32)\n",
    "    h_ = tf.random_uniform([1], minval=margin, maxval=shape[0]-pad_size[0]-margin, dtype=tf.int32)[0]\n",
    "    w_ = tf.random_uniform([1], minval=margin, maxval=shape[1]-pad_size[1]-margin, dtype=tf.int32)[0]\n",
    "    padding = [[h_, shape[0]-h_-pad_size[0]], [w_, shape[1]-w_-pad_size[1]], [0, 0]]\n",
    "    padded = tf.pad(patch, padding, \"CONSTANT\", constant_values=1)\n",
    "    coord = h_, w_\n",
    "    res = tf.multiply(input, padded)\n",
    "    return res, padded, coord, pad_size\n",
    "\n",
    "def load_train_data(args):\n",
    "    \n",
    "    paths = os.path.join(args.img_path, \"img_align_celeba/*.jpg\")\n",
    "    data_count = len(glob(paths))\n",
    "    filenames = tf.train.match_filenames_once(paths)\n",
    "    filename_queue= tf.train.string_input_producer(filenames)\n",
    "    image_reader = tf.WholeFileReader()\n",
    "    _, image_file = image_reader.read(filename_queue)\n",
    "    images = tf.image.decode_jpeg(image_file, channels=3)\n",
    "    images = tf.image.resize_images(images ,[args.input_height, args.input_width])\n",
    "    images = tf.image.convert_image_dtype(images, dtype=tf.float32)/255\n",
    "    orig_images = images\n",
    "    images, mask, coord, pad_size = block_patch(images, margin=args.margin)\n",
    "    mask = tf.reshape(mask, [args.input_height, args.input_height, 3])\n",
    "\n",
    "    #Question: why do we need to flip the mask value\n",
    "    mask = -(mask - 1)\n",
    "    images += mask\n",
    "    orig_imgs, perturbed_imgs, mask, coord, pad_size = tf.train.shuffle_batch([orig_images, images, mask,coord, pad_size],\n",
    "                                                                              args.batch_size,\n",
    "                                                                              capacity=50000,\n",
    "                                                                              min_after_dequeue=10000\n",
    "                                                                              )\n",
    "    return orig_imgs, perturbed_imgs, mask, coord, pad_size, data_count\n",
    "\n",
    "def load_test_data(args):\n",
    "    \n",
    "    paths = glob(\"./data/test/*.jpg\")\n",
    "    data_count = len(paths)\n",
    "\n",
    "    filename_queue = tf.train.string_input_producer(tf.train.match_filenames_once(paths))\n",
    "\n",
    "    image_reader = tf.WholeFileReader()\n",
    "    _, image_file = image_reader.read(filename_queue)\n",
    "    images = tf.image.decode_jpeg(image_file, channels=3)\n",
    "\n",
    "    # uncomment to center crop \n",
    "    # images = tf.image.central_crop(images, 0.5)\n",
    "    images = tf.image.resize_images(images ,[args.input_height, args.input_width])\n",
    "    images = tf.image.convert_image_dtype(images, dtype=tf.float32) /255\n",
    "\n",
    "    orig_images = images\n",
    "    images, mask, coord, pad_size = block_patch(images, margin=args.margin)\n",
    "    mask = tf.reshape(mask, [args.input_height, args.input_height, 3])\n",
    "\n",
    "    #flip mask values\n",
    "    mask = -(mask - 1)\n",
    "    images += mask\n",
    "\n",
    "    orig_imgs, mask, test_imgs = tf.train.batch([orig_images, mask, images],\n",
    "                                                batch_size=args.batch_size,\n",
    "                                                capacity=50000,\n",
    "                                                min_after_dequeue=10000\n",
    "                                                )\n",
    "\n",
    "\n",
    "    return orig_imgs, test_imgs, mask, data_count\n",
    "\n",
    "class network():\n",
    "    def __init__(self, args):\n",
    "\n",
    "        self.batch_size = args.batch_size\n",
    "        self.input_dim = args.input_dim \n",
    "\n",
    "        self.local_width, self.local_height = args.local_input_width, args.local_input_height\n",
    "\n",
    "        self.m = args.margin\n",
    "\n",
    "        self.alpha = args.alpha\n",
    "\n",
    "        #prepare training data\n",
    "        #TODO: improve it by tf.data.Dataset\n",
    "        self.real_img, self.perturbed_img, self.mask, self.coord, self.pads, self.data_count = load_train_data(args)\n",
    "        # self.orig_img, self.test_img, self.test_mask, self.test_data_count = load_test_data(args)\n",
    "        \n",
    "        self.single_orig = tf.placeholder(tf.float32, (args.batch_size, args.input_height, args.input_width, 3))\n",
    "        self.single_test = tf.placeholder(tf.float32, (args.batch_size, args.input_height, args.input_width, 3))\n",
    "        self.single_mask = tf.placeholder(tf.float32, (args.batch_size, args.input_height, args.input_width, 3))\n",
    "\n",
    "        self.build_model()\n",
    "        self.build_loss()\n",
    "\n",
    "        #summary\n",
    "        self.recon_loss_sum = tf.summary.scalar(\"recon_loss\", self.recon_loss) \n",
    "        self.d_loss_sum = tf.summary.scalar(\"d_loss\", self.d_loss) \n",
    "        self.loss_all_sum = tf.summary.scalar(\"loss_all\", self.loss_all)\n",
    "        self.input_img_sum = tf.summary.image(\"input_img\", self.perturbed_img, max_outputs=5)\n",
    "        self.real_img_sum = tf.summary.image(\"real_img\", self.real_img, max_outputs=5)\n",
    "        \n",
    "        self.recon_img_sum = tf.summary.image(\"recon_img\", self.recon_img, max_outputs=5)\n",
    "        self.g_local_imgs_sum = tf.summary.image(\"g_local_imgs\", self.g_local_imgs, max_outputs=5)\n",
    "        self.r_local_imgs_sum = tf.summary.image(\"r_local_imgs\", self.r_local_imgs, max_outputs=5)\n",
    "\n",
    "    #structure of the model\n",
    "    def build_model(self):\n",
    "        def rand_crop(img, coord, pads):\n",
    "            # why do we need to recrop again.\n",
    "            # cut in the same place\n",
    "            #make the label\n",
    "            cropped = tf.image.resize_images(tf.image.crop_to_bounding_box(img, coord[0]-self.m, coord[1]-self.m, pads[0]+self.m*2, pads[1]+self.m*2), (self.local_height, self.local_width))\n",
    "            \n",
    "            return cropped\n",
    "\n",
    "        # uncomment to concatenate mask and masked input image\n",
    "        # self.perturbed_img = tf.concat([self.perturbed_img, self.mask], -1)\n",
    "\n",
    "        self.recon_img, self.g_nets = self.completion_net(self.perturbed_img, name=\"completion_net\")\n",
    "        #why we don't need a - in here\n",
    "        \n",
    "        \n",
    "        self.recon_img = (1-self.mask)*self.real_img + self.mask*self.recon_img\n",
    "\n",
    "        self.test_res_imgs, _ = self.completion_net(self.single_test, name=\"completion_net\", reuse=True)\n",
    "         \n",
    "        self.test_res_imgs = (1-self.single_mask)*self.single_orig + self.single_mask*self.test_res_imgs\n",
    "\n",
    "        self.r_local_imgs = []\n",
    "        self.g_local_imgs = [] \n",
    "        for idx in range(0,self.real_img.shape[0]):\n",
    "            #making the target for local discriminator\n",
    "            r_cropped = rand_crop(self.real_img[idx], self.coord[idx], self.pads[idx])\n",
    "            g_cropped = rand_crop(self.recon_img[idx], self.coord[idx], self.pads[idx])\n",
    "            self.r_local_imgs.append(r_cropped)\n",
    "            self.g_local_imgs.append(g_cropped)\n",
    "\n",
    "        self.r_local_imgs = tf.convert_to_tensor(self.r_local_imgs)\n",
    "        self.g_local_imgs = tf.convert_to_tensor(self.g_local_imgs)\n",
    "        \n",
    "        #global discriminator setting\n",
    "        self.local_fake_d_logits, self.local_fake_d_net = self.local_discriminator(self.g_local_imgs, name=\"local_discriminator\")\n",
    "        self.local_real_d_logits, self.local_real_d_net = self.local_discriminator(self.r_local_imgs, name=\"local_discriminator\", reuse=True)\n",
    "\n",
    "        #local discriminator setting\n",
    "        self.global_fake_d_logits, self.global_fake_d_net = self.global_discriminator(self.recon_img, name=\"global_discriminator\")\n",
    "        self.global_real_d_logits, self.global_real_d_net = self.global_discriminator(self.real_img, name=\"global_discriminator\", reuse=True)\n",
    "        \n",
    "        #print('Before concat a:'+ str(self.local_fake_d_logits.get_shape())+'b:'+str(self.global_fake_d_logits.get_shape()))\n",
    "        \n",
    "        self.fake_d_logits = tf.concat([self.local_fake_d_logits, self.global_fake_d_logits], axis=1)\n",
    "        self.real_d_logits = tf.concat([self.local_real_d_logits, self.global_real_d_logits], axis=1)\n",
    "        \n",
    "        #print('After concat:',self.fake_d_logits.get_shape())\n",
    "        \n",
    "        self.fake_loss = tf.contrib.layers.fully_connected(self.fake_d_logits,1,\n",
    "                                                           activation_fn=tf.nn.sigmoid,\n",
    "                                                           scope='fake_loss')\n",
    "        \n",
    "        self.real_loss = tf.contrib.layers.fully_connected(self.real_d_logits,1,\n",
    "                                                           activation_fn=tf.nn.sigmoid,\n",
    "                                                           #weights_initializer=tf.contrib.layers.xavier_initializer,\n",
    "                                                           scope='real_loss')\n",
    "\n",
    "        #seperate variables\n",
    "        trainable_vars = tf.trainable_variables()\n",
    "        self.c_vars = []\n",
    "        self.d_vars = []\n",
    "        for var in trainable_vars:\n",
    "            if \"completion_net\" in var.name:\n",
    "                self.c_vars.append(var)\n",
    "            else:\n",
    "                self.d_vars.append(var)\n",
    "        #print('C_vars:',len(self.c_vars))\n",
    "        #print('D_vars:',len(self.d_vars))\n",
    "             \n",
    "\n",
    "    #loss function\n",
    "    def build_loss(self):\n",
    "        def calc_loss(logits, label):\n",
    "            if label==1:\n",
    "                y = tf.ones_like(logits)\n",
    "            else:\n",
    "                y = tf.zeros_like(logits)\n",
    "            return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "        \n",
    "        # For updating G in step 1\n",
    "        self.recon_loss = tf.losses.mean_squared_error(self.real_img,self.recon_img,self.mask)\n",
    "        \n",
    "        \n",
    "        # For updating D in step 2\n",
    "        self.fake_d_loss = calc_loss(self.fake_loss, 0)\n",
    "        self.real_d_loss = calc_loss(self.real_loss, 1)\n",
    "        self.d_loss = self.alpha*(self.fake_d_loss + self.real_d_loss)\n",
    "\n",
    "        # For updating G in step 3\n",
    "        self.g_loss = calc_loss(self.fake_loss, 1)\n",
    "        self.loss_all = self.recon_loss + self.alpha*self.g_loss\n",
    "\n",
    "    # completion network \n",
    "    def completion_net(self, input, name=\"generator\", reuse=False):\n",
    "        input_shape = input.get_shape().as_list()\n",
    "        nets = []\n",
    "        with tf.variable_scope(name, reuse=reuse) as scope:\n",
    "            \n",
    "            #print('C_input:',input.get_shape())\n",
    "            conv1 = tf.contrib.layers.conv2d(input,64,\n",
    "                                 kernel_size=5,\n",
    "                                 stride=1,padding='SAME',\n",
    "                                 activation_fn=tf.nn.relu,\n",
    "                                 weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                 biases_initializer=tf.zeros_initializer,\n",
    "                                 normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                 normalizer_params={'scale':True,'scope':'conv_bn1'},\n",
    "                                 scope='conv1')\n",
    "            #print('C_conv1:',conv1.get_shape())\n",
    "            \n",
    "            conv2 = tf.contrib.layers.conv2d(conv1,128,\n",
    "                                 kernel_size=3,\n",
    "                                 stride=2,padding='SAME',\n",
    "                                 activation_fn=tf.nn.relu,\n",
    "                                 weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                 biases_initializer=tf.zeros_initializer,\n",
    "                                 normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                 normalizer_params={'scale':True,'scope':'conv_bn2'},\n",
    "                                 scope='conv2')\n",
    "            #print('C_conv2:',conv2.get_shape())\n",
    "            conv3 = tf.contrib.layers.conv2d(conv2,128,\n",
    "                                 kernel_size=3,\n",
    "                                 stride=1,padding='SAME',\n",
    "                                 activation_fn=tf.nn.relu,\n",
    "                                 weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                 biases_initializer=tf.zeros_initializer,\n",
    "                                 normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                 normalizer_params={'scale':True,'scope':'conv_bn3'},\n",
    "                                 scope='conv3')\n",
    "            #print('C_conv3:',conv3.get_shape())\n",
    "            conv4 = tf.contrib.layers.conv2d(conv3,256,\n",
    "                                 kernel_size=3,\n",
    "                                 stride=2,padding='SAME',\n",
    "                                 activation_fn=tf.nn.relu,\n",
    "                                 weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                 biases_initializer=tf.zeros_initializer,\n",
    "                                 normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                 normalizer_params={'scale':True,'scope':'conv_bn4'},\n",
    "                                 scope='conv4')\n",
    "            #print('C_conv4:',conv4.get_shape())\n",
    "            conv5 = tf.contrib.layers.conv2d(conv4,256,\n",
    "                                 kernel_size=3,\n",
    "                                 stride=1,padding='SAME',\n",
    "                                 activation_fn=tf.nn.relu,\n",
    "                                 weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                 biases_initializer=tf.zeros_initializer,\n",
    "                                 normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                 normalizer_params={'scale':True,'scope':'conv_bn5'},\n",
    "                                 scope='conv5')\n",
    "            #print('C_conv5:',conv5.get_shape())\n",
    "            conv6 = tf.contrib.layers.conv2d(conv5,256,\n",
    "                                 kernel_size=3,\n",
    "                                 stride=1,padding='SAME',\n",
    "                                 activation_fn=tf.nn.relu,\n",
    "                                 weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                 biases_initializer=tf.zeros_initializer,\n",
    "                                 normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                 normalizer_params={'scale':True,'scope':'conv_bn6'},\n",
    "                                 scope='conv6')\n",
    "            \n",
    "            #Dilated conv from here\n",
    "            \n",
    "            dilate_conv1 = tf.layers.conv2d(conv6,256,3,strides=1,padding='SAME',dilation_rate=2,\n",
    "                                           kernel_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                           name=\"dilate_conv1\")\n",
    "            dilate_conv1 = tf.contrib.layers.batch_norm(dilate_conv1,scale=True,\n",
    "                                                       scope='dilate_bn1',activation_fn=tf.nn.relu)\n",
    "            \n",
    "            #print('C_dilated_conv1:',dilate_conv1.get_shape())\n",
    "            \n",
    "            dilate_conv2 = tf.layers.conv2d(dilate_conv1,256,3,strides=1,padding='SAME',dilation_rate=4,\n",
    "                                           kernel_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                           name=\"dilate_conv2\")\n",
    "            dilate_conv2 = tf.contrib.layers.batch_norm(dilate_conv2,scale=True,\n",
    "                                                       scope='dilate_bn2',activation_fn=tf.nn.relu)\n",
    "            \n",
    "            #print('C_dilated_conv2:',dilate_conv2.get_shape())\n",
    "            \n",
    "            dilate_conv3 = tf.layers.conv2d(dilate_conv2,256,3,strides=1,padding='SAME',dilation_rate=8,\n",
    "                                           kernel_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                           name=\"dilate_conv3\")\n",
    "            dilate_conv3 = tf.contrib.layers.batch_norm(dilate_conv3,scale=True,\n",
    "                                                       scope='dilate_bn3',activation_fn=tf.nn.relu)\n",
    "            \n",
    "            #print('C_dilated_conv3:',dilate_conv3.get_shape())\n",
    "            \n",
    "            dilate_conv4 = tf.layers.conv2d(dilate_conv3,256,3,strides=1,padding='SAME',dilation_rate=16,\n",
    "                                           kernel_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                           name=\"dilate_conv4\")\n",
    "            dilate_conv4 = tf.contrib.layers.batch_norm(dilate_conv3,scale=True,\n",
    "                                                       scope='dilate_bn4',activation_fn=tf.nn.relu)\n",
    "            \n",
    "            #print('C_dilated_conv4:',dilate_conv4.get_shape())\n",
    "\n",
    "            #resize back\n",
    "            \n",
    "            conv7 = tf.contrib.layers.conv2d(dilate_conv4,256,\n",
    "                                 kernel_size=3,\n",
    "                                 stride=1,padding='SAME',\n",
    "                                 activation_fn=tf.nn.relu,\n",
    "                                 weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                 biases_initializer=tf.zeros_initializer,\n",
    "                                 normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                 normalizer_params={'scale':True,'scope':'conv_bn7'},\n",
    "                                 scope='conv7')\n",
    "            \n",
    "            #print('C_conv7:',conv7.get_shape())\n",
    "            conv8 = tf.contrib.layers.conv2d(conv7,256,\n",
    "                                 kernel_size=3,\n",
    "                                 stride=1,padding='SAME',\n",
    "                                 activation_fn=tf.nn.relu,\n",
    "                                 weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                 biases_initializer=tf.zeros_initializer,\n",
    "                                 normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                 normalizer_params={'scale':True,'scope':'conv_bn8'},\n",
    "                                 scope='conv8')\n",
    "            #print('C_conv8:',conv8.get_shape())\n",
    "            deconv1 = tf.layers.conv2d_transpose(conv8,128,4,strides=2,\n",
    "                                                    padding=\"SAME\",\n",
    "                                                    use_bias=False,\n",
    "                                                    name=\"deconv1\",\n",
    "                                                    kernel_initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "            tf.contrib.layers.batch_norm(deconv1,scale=True,scope='deconv_bn1',activation_fn=tf.nn.relu)\n",
    "            \n",
    "            #print('C_deconv1:',deconv1.get_shape())\n",
    "            \n",
    "            conv9 = tf.contrib.layers.conv2d(deconv1,128,\n",
    "                                 kernel_size=3,\n",
    "                                 stride=1,padding='SAME',\n",
    "                                 activation_fn=tf.nn.relu,\n",
    "                                 weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                 biases_initializer=tf.zeros_initializer,\n",
    "                                 normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                 normalizer_params={'scale':True,'scope':'conv_bn9'},\n",
    "                                 scope='conv9')\n",
    "\n",
    "            #print('C_conv9:',conv9.get_shape())\n",
    "            \n",
    "            deconv2 = tf.layers.conv2d_transpose(conv9,64,4,strides=2,\n",
    "                                                    padding=\"SAME\",\n",
    "                                                    use_bias=False,\n",
    "                                                    name=\"deconv2\",\n",
    "                                                    kernel_initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "            tf.contrib.layers.batch_norm(deconv2,scale=True,scope='deconv_bn2',activation_fn=tf.nn.relu)\n",
    "            \n",
    "            #print('C_deconv2:',deconv2.get_shape())\n",
    "            conv10 = tf.contrib.layers.conv2d(deconv2,32,\n",
    "                                 kernel_size=3,\n",
    "                                 stride=1,padding='SAME',\n",
    "                                 activation_fn=tf.nn.relu,\n",
    "                                 weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                 biases_initializer=tf.zeros_initializer,\n",
    "                                 normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                 normalizer_params={'scale':True,'scope':'conv_bn10'},\n",
    "                                 scope='conv10')\n",
    "            \n",
    "            #print('C_conv10:',conv10.get_shape())\n",
    "            conv11 = tf.contrib.layers.conv2d(conv10,3,\n",
    "                                 kernel_size=3,\n",
    "                                 stride=1,padding='SAME',\n",
    "                                 activation_fn=tf.nn.sigmoid,\n",
    "                                 weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                 biases_initializer=tf.zeros_initializer,\n",
    "                                 scope='conv11')\n",
    "            #print('C_conv11:',conv11.get_shape())   \n",
    "            return conv11, nets\n",
    "\n",
    "    # D network from DCGAN\n",
    "    def local_discriminator(self, input, name=\"local_discriminator\", reuse=False):\n",
    "        nets = []\n",
    "        with tf.variable_scope(name, reuse=reuse) as scope:\n",
    "            \n",
    "            #print('L_input:',input.get_shape())\n",
    "            conv1 = tf.contrib.layers.conv2d(input, 64, 5, 2,\n",
    "                                             padding=\"SAME\",\n",
    "                                             activation_fn=tf.nn.relu,\n",
    "                                             weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                             biases_initializer=tf.zeros_initializer,\n",
    "                                             normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                             normalizer_params={'scale':True,'scope':'bn1'},\n",
    "                                             scope='conv1')\n",
    "            nets.append(conv1)\n",
    "            #print('L_conv1:',conv1.get_shape())\n",
    "            conv2 = tf.contrib.layers.conv2d(conv1, 128, 5, 2,\n",
    "                                             padding='SAME',\n",
    "                                             activation_fn=tf.nn.relu,\n",
    "                                             weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                             biases_initializer=tf.zeros_initializer,\n",
    "                                             normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                             normalizer_params={'scale':True,'scope':'bn2'},\n",
    "                                             scope='conv2')\n",
    "            nets.append(conv2)\n",
    "            #print('L_conv2:',conv2.get_shape())\n",
    "            conv3 = tf.contrib.layers.conv2d(conv2, 256, 5, 2,\n",
    "                                             padding='SAME',\n",
    "                                             activation_fn=tf.nn.relu,\n",
    "                                             weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                             biases_initializer=tf.zeros_initializer,\n",
    "                                             normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                             normalizer_params={'scale':True,'scope':'bn3'},\n",
    "                                             scope='conv3')\n",
    "            nets.append(conv3)\n",
    "            #print('L_conv3:',conv3.get_shape())\n",
    "            conv4 = tf.contrib.layers.conv2d(conv3, 512, 5, 2,\n",
    "                                             padding='SAME',\n",
    "                                             activation_fn=tf.nn.relu,\n",
    "                                             weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                             biases_initializer=tf.zeros_initializer,\n",
    "                                             normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                             normalizer_params={'scale':True,'scope':'bn4'},\n",
    "                                             scope='conv4')\n",
    "            nets.append(conv4)\n",
    "\n",
    "            #print('L_conv4:',conv4.get_shape())\n",
    "\n",
    "            flatten = tf.contrib.layers.flatten(conv4)\n",
    "            \n",
    "            output = tf.contrib.layers.fully_connected(flatten,1024,\n",
    "                                                       activation_fn=tf.nn.relu,\n",
    "                                                       scope='L_linear')\n",
    "\n",
    "            return output, nets\n",
    "\n",
    "\n",
    "\n",
    "    def global_discriminator(self, input, name=\"global_discriminator\", reuse=False):\n",
    "        nets = []\n",
    "        with tf.variable_scope(name, reuse=reuse) as scope:\n",
    "            #print('G_input:',input.get_shape())\n",
    "            conv1 = tf.contrib.layers.conv2d(input, 64, 5, 2,\n",
    "                                     padding=\"SAME\",\n",
    "                                     activation_fn=tf.nn.relu,\n",
    "                                     weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                     biases_initializer=tf.zeros_initializer,\n",
    "                                     normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                     normalizer_params={'scale':True,'scope':'bn1'},\n",
    "                                     scope='conv1')\n",
    "            nets.append(conv1)\n",
    "            #print('G_conv1:',conv1.get_shape())\n",
    "\n",
    "            conv2 = tf.contrib.layers.conv2d(conv1, 128, 5, 2,\n",
    "                                     padding=\"SAME\",\n",
    "                                     activation_fn=tf.nn.relu,\n",
    "                                     weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                     biases_initializer=tf.zeros_initializer,\n",
    "                                     normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                     normalizer_params={'scale':True,'scope':'bn2'},\n",
    "                                     scope='conv2')\n",
    "            nets.append(conv2)\n",
    "            #print('G_conv2:',conv2.get_shape())\n",
    "\n",
    "            conv3 = tf.contrib.layers.conv2d(conv2, 256, 5, 2,\n",
    "                                     padding=\"SAME\",\n",
    "                                     activation_fn=tf.nn.relu,\n",
    "                                     weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                     biases_initializer=tf.zeros_initializer,\n",
    "                                     normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                     normalizer_params={'scale':True,'scope':'bn3'},\n",
    "                                     scope='conv3')\n",
    "        \n",
    "            nets.append(conv3)\n",
    "            #print('G_conv3:',conv3.get_shape())\n",
    "\n",
    "            conv4 = tf.contrib.layers.conv2d(conv3, 512, 5, 2,\n",
    "                                             padding=\"SAME\",\n",
    "                                             activation_fn=tf.nn.relu,\n",
    "                                             weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                             biases_initializer=tf.zeros_initializer,\n",
    "                                             normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                             normalizer_params={'scale':True,'scope':'bn4'},\n",
    "                                             scope='conv4')\n",
    "      \n",
    "            nets.append(conv4)\n",
    "            #print('G_conv4:',conv4.get_shape())\n",
    "\n",
    "            conv5 = tf.contrib.layers.conv2d(conv4, 512, 5, 2,\n",
    "                                             padding=\"SAME\",\n",
    "                                             activation_fn=tf.nn.relu,\n",
    "                                             weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                             biases_initializer=tf.zeros_initializer,\n",
    "                                             normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                             normalizer_params={'scale':True,'scope':'bn5'},\n",
    "                                             scope='conv5')\n",
    "            \n",
    "            nets.append(conv5)\n",
    "            #print('G_conv5:',conv5.get_shape())\n",
    "\n",
    "            flatten = tf.contrib.layers.flatten(conv5)\n",
    "            \n",
    "            output = tf.contrib.layers.fully_connected(flatten,1024,\n",
    "                                                       activation_fn=tf.nn.relu,\n",
    "                                                       scope='G_linear')\n",
    "\n",
    "            return output, nets\n",
    "\n",
    "def train(args, sess, model):\n",
    "    # Adam optimizers are used instead of AdaDelta\n",
    "    # Use var_list to restrict the gradient\n",
    "    d_optimizer = tf.train.AdamOptimizer(args.learning_rate, beta1=args.momentum, name=\"AdamOptimizer_D\").minimize(model.d_loss, var_list=model.d_vars)\n",
    "    c_optimizer = tf.train.AdamOptimizer(args.learning_rate, beta1=args.momentum, name=\"AdamOptimizer_C\").minimize(model.recon_loss, var_list=model.c_vars)\n",
    "    global_optimizer = tf.train.AdamOptimizer(args.learning_rate, beta1=args.momentum, name=\"AdamOptimizer_C\").minimize(model.loss_all, var_list=model.c_vars)\n",
    "\n",
    "    epoch = 0\n",
    "    step = 1\n",
    "    global_step = 0\n",
    "\n",
    "    saver = tf.train.Saver()        \n",
    "    if args.continue_training:\n",
    "        tf.local_variables_initializer().run()\n",
    "        last_ckpt = tf.train.latest_checkpoint(args.checkpoints_path)\n",
    "        saver.restore(sess, last_ckpt)\n",
    "        ckpt_name = str(last_ckpt)\n",
    "        print (\"Loaded model file from \" + ckpt_name)\n",
    "        step = int(ckpt_name.split('-')[-1])\n",
    "    else:\n",
    "        tf.global_variables_initializer().run()\n",
    "        tf.local_variables_initializer().run()\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "    #summary init\n",
    "    all_summary = tf.summary.merge([model.recon_loss_sum,\n",
    "                                    model.d_loss_sum,\n",
    "                                    model.loss_all_sum,\n",
    "                                    model.input_img_sum, \n",
    "                                    model.real_img_sum,\n",
    "                                    model.recon_img_sum,\n",
    "                                    model.g_local_imgs_sum,\n",
    "                                    model.r_local_imgs_sum])\n",
    "    writer = tf.summary.FileWriter(args.graph_path, sess.graph)\n",
    "\n",
    "    # Training strating point\n",
    "    while step < args.train_step:\n",
    "\n",
    "        #Training Stage 1 (Completion Network)\n",
    "        if step < args.Tc:\n",
    "            # the main training step is the optimizer <only optimizing classify>\n",
    "            # Treat it as a decoder\n",
    "            summary, c_loss, _ = sess.run([all_summary, model.recon_loss, c_optimizer])\n",
    "            writer.add_summary(summary, step)\n",
    "            print (\"Epoch [%d] Step [%d] C Loss: [%.4f]\" % (epoch, step, c_loss))\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            #Training Stage 2 (Discriminator Network)\n",
    "            summary, d_loss, _ = sess.run([all_summary, model.d_loss, d_optimizer])\n",
    "            writer.add_summary(summary, step)\n",
    "            print (\"Epoch [%d] Step [%d] D Loss: [%.4f]\" % (epoch, step, d_loss))\n",
    "            \n",
    "            if step > args.Tc + args.Td:\n",
    "                #Training Stage 3 (Completion Network)\n",
    "                summary, g_loss, _ = sess.run([all_summary, model.loss_all, global_optimizer])\n",
    "                writer.add_summary(summary, global_step)\n",
    "                print (\"Epoch [%d] Step [%d] G Loss: [%.4f]\" % (epoch, step, g_loss))\n",
    "        \n",
    "        # Show the training image\n",
    "        if step % args.show_freq ==0:            \n",
    "            fig = plt.figure()\n",
    "            fig.add_subplot(1,2,1)\n",
    "            plt.imshow(np.asarray(sess.run(model.recon_img)[0]))\n",
    "            plt.show()\n",
    "\n",
    "        # Check Test image results every time epoch is finished\n",
    "        if step*args.batch_size >= model.data_count:\n",
    "            saver.save(sess, args.checkpoints_path + \"/model\",global_step=step)\n",
    "            \n",
    "        step += 1\n",
    "        \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    sess.close()            \n",
    "    print(\"Done.\")\n",
    "\n",
    "    \n",
    "# Testing Variables\n",
    "drawing = False \n",
    "ix,iy = -1,-1\n",
    "color = (255,255,255)\n",
    "size = 10    \n",
    "       \n",
    "def erase_img(args, img):\n",
    "\n",
    "    # mouse callback function\n",
    "    def erase_rect(event,x,y,flags,param):\n",
    "        global ix,iy,drawing\n",
    "\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            drawing = True\n",
    "            if drawing == True:\n",
    "                # cv2.circle(img,(x,y),10,(255,255,255),-1)\n",
    "                cv2.rectangle(img,(x-size,y-size),(x+size,y+size),color,-1)\n",
    "                cv2.rectangle(mask,(x-size,y-size),(x+size,y+size),color,-1)\n",
    "            \n",
    "        elif event == cv2.EVENT_MOUSEMOVE:\n",
    "            if drawing == True:\n",
    "                # cv2.circle(img,(x,y),10,(255,255,255),-1)\n",
    "                cv2.rectangle(img,(x-size,y-size),(x+size,y+size),color,-1)\n",
    "                cv2.rectangle(mask,(x-size,y-size),(x+size,y+size),color,-1)\n",
    "        elif event == cv2.EVENT_LBUTTONUP:\n",
    "            drawing = False\n",
    "            # cv2.circle(img,(x,y),10,(255,255,255),-1)\n",
    "            cv2.rectangle(img,(x-size,y-size),(x+size,y+size),color,-1)\n",
    "            cv2.rectangle(mask,(x-size,y-size),(x+size,y+size),color,-1)\n",
    "\n",
    "\n",
    "    cv2.namedWindow('image')\n",
    "    cv2.setMouseCallback('image',erase_rect)\n",
    "    #cv2.namedWindow('mask')\n",
    "    cv2.setMouseCallback('mask',erase_rect)\n",
    "    mask = np.zeros(img.shape)\n",
    "    \n",
    "\n",
    "    while(1):\n",
    "        img_show = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        cv2.imshow('image',img_show)\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "        if k == 10:\n",
    "            break\n",
    "            \n",
    "    test_img = cv2.resize(img, (args.input_height, args.input_width))/255.0\n",
    "    test_mask = cv2.resize(mask, (args.input_height, args.input_width))/255.0\n",
    "    #fill mask region to 1\n",
    "    test_img = (test_img * (1-test_mask)) + test_mask\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    return np.tile(test_img[np.newaxis,:], [args.batch_size,1,1,1]), np.tile(test_mask[np.newaxis,:], [args.batch_size,1,1,1])\n",
    "\n",
    "\n",
    "def test(args, sess, model):\n",
    "    #saver  \n",
    "    saver = tf.train.Saver()        \n",
    "    last_ckpt = tf.train.latest_checkpoint(args.checkpoints_path)\n",
    "    saver.restore(sess, last_ckpt)\n",
    "    ckpt_name = str(last_ckpt)\n",
    "    print (\"Loaded model file from \" + ckpt_name)\n",
    "    \n",
    "    img = cv2.imread(args.img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    orig_test = cv2.resize(img, (args.input_height, args.input_width))/127.5 - 1\n",
    "    orig_test = np.tile(orig_test[np.newaxis,:],[args.batch_size,1,1,1])\n",
    "    orig_test = orig_test.astype(np.float32)\n",
    "\n",
    "    orig_w, orig_h = img.shape[0], img.shape[1]\n",
    "    test_img, mask = erase_img(args, img)\n",
    "    test_img = test_img.astype(np.float32)\n",
    "    \n",
    "    print (\"Testing ...\")\n",
    "    res_img = sess.run(model.test_res_imgs, feed_dict={model.single_orig:orig_test,\n",
    "                                                       model.single_test:test_img,\n",
    "                                                       model.single_mask:mask})\n",
    "\n",
    "    orig = cv2.resize((orig_test[0]+1)//2, (orig_h//2, orig_w//2))\n",
    "    test = cv2.resize((test_img[0]+1)//2, (orig_h//2, orig_w//2))\n",
    "    recon = cv2.resize((res_img[0]+1)//2, (orig_h//2, orig_w//2))\n",
    "\n",
    "    res = np.hstack([orig,test,recon])\n",
    "    res = cv2.cvtColor(res, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    cv2.imshow(\"result\", res)\n",
    "    cv2.waitKey()\n",
    "\n",
    "    print(\"Done.\")\n",
    "\n",
    "    \n",
    "def main_test(_):\n",
    "    run_config = tf.ConfigProto()\n",
    "    run_config.gpu_options.allow_growth = True\n",
    "    \n",
    "    with tf.Session(config=run_config) as sess:\n",
    "        model = network(args)\n",
    "\n",
    "        print ('Start Testing...')\n",
    "        test(args, sess, model)    \n",
    "    \n",
    "    \n",
    "def main_train(_):\n",
    "    run_config = tf.ConfigProto()\n",
    "    run_config.gpu_options.allow_growth = True\n",
    "\n",
    "    # Setting folders\n",
    "    if not os.path.exists(args.checkpoints_path):\n",
    "        os.makedirs(args.checkpoints_path)\n",
    "    if not os.path.exists(args.graph_path):\n",
    "        os.makedirs(args.graph_path)\n",
    "    if not os.path.exists(args.images_path):\n",
    "        os.makedirs(args.images_path)\n",
    "        \n",
    "    with tf.Session(config=run_config) as sess:\n",
    "        model = network(args)\n",
    "        print ('Start Training...')\n",
    "        train(args, sess, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "Epoch [0] Step [1] C Loss: [0.0785]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "args= Parser()        \n",
    "tf.reset_default_graph()\n",
    "main_train(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing (Need model)\n",
    "\n",
    "#tf.reset_default_graph()\n",
    "#main_test(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
