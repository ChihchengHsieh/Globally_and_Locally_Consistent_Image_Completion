{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#TODO: DataLoader\n",
    "#TODO: GANestimator\n",
    "\n",
    "\n",
    "class Parser():\n",
    "    #hyperparameters\n",
    "    def __init__(self):\n",
    "        #image setting\n",
    "        self.input_width=64\n",
    "        self.input_height=64\n",
    "        self.local_input_width=32\n",
    "        self.local_input_height=32\n",
    "        self.input_channel=3\n",
    "        self.input_dim=100\n",
    "        \n",
    "        #Training settings\n",
    "        self.continue_training=False\n",
    "        self.data='./'\n",
    "        self.batch_size=128\n",
    "        self.train_step=500000#400\n",
    "        self.Tc=90000\n",
    "        self.Td=10000\n",
    "        self.learning_rate=0.001\n",
    "        self.momentum=0.5\n",
    "        self.show_freq=20 # How many iteration will show a example\n",
    "        \n",
    "        #set alpha to 1 to give more weights to the discriminator loss\n",
    "        self.alpha=0.004\n",
    "        self.margin=5\n",
    "        self.img_path='./'\n",
    "        self.checkpoints_path='./checkpoint/'\n",
    "        self.graph_path='./graphs/'\n",
    "        self.images_path='./images/'\n",
    "\n",
    "def block_patch(input, margin=5):\n",
    "    shape = input.get_shape().as_list()\n",
    "    #create patch in random size\n",
    "    pad_size = tf.random_uniform([2], minval=15, maxval=25, dtype=tf.int32)\n",
    "    patch = tf.zeros([pad_size[0], pad_size[1], shape[-1]], dtype=tf.float32)\n",
    "    h_ = tf.random_uniform([1], minval=margin, maxval=shape[0]-pad_size[0]-margin, dtype=tf.int32)[0]\n",
    "    w_ = tf.random_uniform([1], minval=margin, maxval=shape[1]-pad_size[1]-margin, dtype=tf.int32)[0]\n",
    "    padding = [[h_, shape[0]-h_-pad_size[0]], [w_, shape[1]-w_-pad_size[1]], [0, 0]]\n",
    "    padded = tf.pad(patch, padding, \"CONSTANT\", constant_values=1)\n",
    "    coord = h_, w_\n",
    "    res = tf.multiply(input, padded)\n",
    "    return res, padded, coord, pad_size\n",
    "\n",
    "def load_train_data(args):\n",
    "    \n",
    "    paths = os.path.join(args.img_path, \"img_align_celeba/*.jpg\")\n",
    "    data_count = len(glob(paths))\n",
    "    filenames = tf.train.match_filenames_once(paths)\n",
    "    filename_queue= tf.train.string_input_producer(filenames)\n",
    "    image_reader = tf.WholeFileReader()\n",
    "    _, image_file = image_reader.read(filename_queue)\n",
    "    images = tf.image.decode_jpeg(image_file, channels=3)\n",
    "    images = tf.image.resize_images(images ,[args.input_height, args.input_width])\n",
    "    images = tf.image.convert_image_dtype(images, dtype=tf.float32)/255\n",
    "    orig_images = images\n",
    "    images, mask, coord, pad_size = block_patch(images, margin=args.margin)\n",
    "    mask = tf.reshape(mask, [args.input_height, args.input_height, 3])\n",
    "\n",
    "    #Question: why do we need to flip the mask value\n",
    "    mask = -(mask - 1)\n",
    "    images += mask\n",
    "    orig_imgs, perturbed_imgs, mask, coord, pad_size = tf.train.shuffle_batch([orig_images, images, mask,coord, pad_size],\n",
    "                                                                              args.batch_size,\n",
    "                                                                              capacity=50000,\n",
    "                                                                              min_after_dequeue=10000\n",
    "                                                                              )\n",
    "    return orig_imgs, perturbed_imgs, mask, coord, pad_size, data_count\n",
    "\n",
    "def load_test_data(args):\n",
    "    \n",
    "    paths = glob(\"./data/test/*.jpg\")\n",
    "    data_count = len(paths)\n",
    "\n",
    "    filename_queue = tf.train.string_input_producer(tf.train.match_filenames_once(paths))\n",
    "\n",
    "    image_reader = tf.WholeFileReader()\n",
    "    _, image_file = image_reader.read(filename_queue)\n",
    "    images = tf.image.decode_jpeg(image_file, channels=3)\n",
    "\n",
    "    # uncomment to center crop \n",
    "    # images = tf.image.central_crop(images, 0.5)\n",
    "    images = tf.image.resize_images(images ,[args.input_height, args.input_width])\n",
    "    images = tf.image.convert_image_dtype(images, dtype=tf.float32) /255\n",
    "\n",
    "    orig_images = images\n",
    "    images, mask, coord, pad_size = block_patch(images, margin=args.margin)\n",
    "    mask = tf.reshape(mask, [args.input_height, args.input_height, 3])\n",
    "\n",
    "    #flip mask values\n",
    "    mask = -(mask - 1)\n",
    "    images += mask\n",
    "\n",
    "    orig_imgs, mask, test_imgs = tf.train.batch([orig_images, mask, images],\n",
    "                                                batch_size=args.batch_size,\n",
    "                                                capacity=50000,\n",
    "                                                min_after_dequeue=10000\n",
    "                                                )\n",
    "\n",
    "\n",
    "    return orig_imgs, test_imgs, mask, data_count\n",
    "\n",
    "class network():\n",
    "    def __init__(self, args):\n",
    "\n",
    "        self.batch_size = args.batch_size\n",
    "        self.input_dim = args.input_dim \n",
    "\n",
    "        self.local_width, self.local_height = args.local_input_width, args.local_input_height\n",
    "\n",
    "        self.m = args.margin\n",
    "\n",
    "        self.alpha = args.alpha\n",
    "\n",
    "        #prepare training data\n",
    "        #TODO: improve it by tf.data.Dataset\n",
    "        self.real_img, self.perturbed_img, self.mask, self.coord, self.pads, self.data_count = load_train_data(args)\n",
    "        # self.orig_img, self.test_img, self.test_mask, self.test_data_count = load_test_data(args)\n",
    "        \n",
    "        self.single_orig = tf.placeholder(tf.float32, (args.batch_size, args.input_height, args.input_width, 3))\n",
    "        self.single_test = tf.placeholder(tf.float32, (args.batch_size, args.input_height, args.input_width, 3))\n",
    "        self.single_mask = tf.placeholder(tf.float32, (args.batch_size, args.input_height, args.input_width, 3))\n",
    "\n",
    "        self.build_model()\n",
    "        self.build_loss()\n",
    "\n",
    "        #summary\n",
    "        self.recon_loss_sum = tf.summary.scalar(\"recon_loss\", self.recon_loss) \n",
    "        self.d_loss_sum = tf.summary.scalar(\"d_loss\", self.d_loss) \n",
    "        self.loss_all_sum = tf.summary.scalar(\"loss_all\", self.loss_all)\n",
    "        self.input_img_sum = tf.summary.image(\"input_img\", self.perturbed_img, max_outputs=5)\n",
    "        self.real_img_sum = tf.summary.image(\"real_img\", self.real_img, max_outputs=5)\n",
    "        \n",
    "        self.recon_img_sum = tf.summary.image(\"recon_img\", self.recon_img, max_outputs=5)\n",
    "        self.g_local_imgs_sum = tf.summary.image(\"g_local_imgs\", self.g_local_imgs, max_outputs=5)\n",
    "        self.r_local_imgs_sum = tf.summary.image(\"r_local_imgs\", self.r_local_imgs, max_outputs=5)\n",
    "\n",
    "    #structure of the model\n",
    "    def build_model(self):\n",
    "        def rand_crop(img, coord, pads):\n",
    "            # why do we need to recrop again.\n",
    "            # cut in the same place\n",
    "            #make the label\n",
    "            cropped = tf.image.resize_images(tf.image.crop_to_bounding_box(img, coord[0]-self.m, coord[1]-self.m, pads[0]+self.m*2, pads[1]+self.m*2), (self.local_height, self.local_width))\n",
    "            \n",
    "            return cropped\n",
    "\n",
    "        # uncomment to concatenate mask and masked input image\n",
    "        # self.perturbed_img = tf.concat([self.perturbed_img, self.mask], -1)\n",
    "\n",
    "        self.recon_img, self.g_nets = self.completion_net(self.perturbed_img, name=\"completion_net\")\n",
    "        #why we don't need a - in here\n",
    "        \n",
    "        \n",
    "        self.recon_img = (1-self.mask)*self.real_img + self.mask*self.recon_img\n",
    "\n",
    "        self.test_res_imgs, _ = self.completion_net(self.single_test, name=\"completion_net\", reuse=True)\n",
    "         \n",
    "        self.test_res_imgs = (1-self.single_mask)*self.single_orig + self.single_mask*self.test_res_imgs\n",
    "\n",
    "        self.r_local_imgs = []\n",
    "        self.g_local_imgs = [] \n",
    "        for idx in range(0,self.real_img.shape[0]):\n",
    "            #making the target for local discriminator\n",
    "            r_cropped = rand_crop(self.real_img[idx], self.coord[idx], self.pads[idx])\n",
    "            g_cropped = rand_crop(self.recon_img[idx], self.coord[idx], self.pads[idx])\n",
    "            self.r_local_imgs.append(r_cropped)\n",
    "            self.g_local_imgs.append(g_cropped)\n",
    "\n",
    "        self.r_local_imgs = tf.convert_to_tensor(self.r_local_imgs)\n",
    "        self.g_local_imgs = tf.convert_to_tensor(self.g_local_imgs)\n",
    "        \n",
    "        #global discriminator setting\n",
    "        self.local_fake_d_logits, self.local_fake_d_net = self.local_discriminator(self.g_local_imgs, name=\"local_discriminator\")\n",
    "        self.local_real_d_logits, self.local_real_d_net = self.local_discriminator(self.r_local_imgs, name=\"local_discriminator\", reuse=True)\n",
    "\n",
    "        #local discriminator setting\n",
    "        self.global_fake_d_logits, self.global_fake_d_net = self.global_discriminator(self.recon_img, name=\"global_discriminator\")\n",
    "        self.global_real_d_logits, self.global_real_d_net = self.global_discriminator(self.real_img, name=\"global_discriminator\", reuse=True)\n",
    "        \n",
    "        #print('Before concat a:'+ str(self.local_fake_d_logits.get_shape())+'b:'+str(self.global_fake_d_logits.get_shape()))\n",
    "        \n",
    "        self.fake_d_logits = tf.concat([self.local_fake_d_logits, self.global_fake_d_logits], axis=1)\n",
    "        self.real_d_logits = tf.concat([self.local_real_d_logits, self.global_real_d_logits], axis=1)\n",
    "        \n",
    "        #print('After concat:',self.fake_d_logits.get_shape())\n",
    "        \n",
    "        self.fake_loss = tf.contrib.layers.fully_connected(self.fake_d_logits,1,\n",
    "                                                           scope='fake_loss')\n",
    "        \n",
    "        self.real_loss = tf.contrib.layers.fully_connected(self.real_d_logits,1,\n",
    "                                                           scope='real_loss')\n",
    "\n",
    "        #seperate variables\n",
    "        trainable_vars = tf.trainable_variables()\n",
    "        self.c_vars = []\n",
    "        self.d_vars = []\n",
    "        for var in trainable_vars:\n",
    "            if \"completion_net\" in var.name:\n",
    "                self.c_vars.append(var)\n",
    "            else:\n",
    "                self.d_vars.append(var)\n",
    "        #print('C_vars:',len(self.c_vars))\n",
    "        #print('D_vars:',len(self.d_vars))\n",
    "             \n",
    "    #loss function\n",
    "    def build_loss(self):\n",
    "        def calc_loss(logits, label):\n",
    "            if label==1:\n",
    "                y = tf.ones_like(logits)\n",
    "            else:\n",
    "                y = tf.zeros_like(logits)\n",
    "            return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "        \n",
    "        # For updating G in step 1\n",
    "        self.recon_loss = tf.losses.mean_squared_error(self.real_img,self.recon_img,self.mask)\n",
    "        \n",
    "        # For updating D in step 2\n",
    "        self.fake_d_loss = calc_loss(self.fake_loss, 0)\n",
    "        self.real_d_loss = calc_loss(self.real_loss, 1)\n",
    "        self.d_loss = self.alpha*(self.fake_d_loss + self.real_d_loss)\n",
    "\n",
    "        # For updating G in step 3\n",
    "        self.g_loss = calc_loss(self.fake_loss, 1)\n",
    "        self.loss_all = self.recon_loss + self.alpha*self.g_loss\n",
    "\n",
    "    # completion network \n",
    "    def completion_net(self, input, name=\"generator\", reuse=False):\n",
    "        input_shape = input.get_shape().as_list()\n",
    "        nets = []\n",
    "        with tf.variable_scope(name, reuse=reuse) as scope:\n",
    "            \n",
    "            #print('C_input:',input.get_shape())\n",
    "            conv1 = tf.contrib.layers.conv2d(input,64,\n",
    "                                 kernel_size=5,\n",
    "                                 stride=1,padding='SAME',\n",
    "                                 activation_fn=tf.nn.relu,\n",
    "                                 weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                 biases_initializer=tf.zeros_initializer,\n",
    "                                 normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                 normalizer_params={'scale':True,'scope':'conv_bn1'},\n",
    "                                 scope='conv1')\n",
    "            #print('C_conv1:',conv1.get_shape())\n",
    "            \n",
    "            conv2 = tf.contrib.layers.conv2d(conv1,128,\n",
    "                                 kernel_size=3,\n",
    "                                 stride=2,padding='SAME',\n",
    "                                 activation_fn=tf.nn.relu,\n",
    "                                 weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                 biases_initializer=tf.zeros_initializer,\n",
    "                                 normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                 normalizer_params={'scale':True,'scope':'conv_bn2'},\n",
    "                                 scope='conv2')\n",
    "            #print('C_conv2:',conv2.get_shape())\n",
    "            conv3 = tf.contrib.layers.conv2d(conv2,128,\n",
    "                                 kernel_size=3,\n",
    "                                 stride=1,padding='SAME',\n",
    "                                 activation_fn=tf.nn.relu,\n",
    "                                 weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                 biases_initializer=tf.zeros_initializer,\n",
    "                                 normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                 normalizer_params={'scale':True,'scope':'conv_bn3'},\n",
    "                                 scope='conv3')\n",
    "            #print('C_conv3:',conv3.get_shape())\n",
    "            conv4 = tf.contrib.layers.conv2d(conv3,256,\n",
    "                                 kernel_size=3,\n",
    "                                 stride=2,padding='SAME',\n",
    "                                 activation_fn=tf.nn.relu,\n",
    "                                 weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                 biases_initializer=tf.zeros_initializer,\n",
    "                                 normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                 normalizer_params={'scale':True,'scope':'conv_bn4'},\n",
    "                                 scope='conv4')\n",
    "            #print('C_conv4:',conv4.get_shape())\n",
    "            conv5 = tf.contrib.layers.conv2d(conv4,256,\n",
    "                                 kernel_size=3,\n",
    "                                 stride=1,padding='SAME',\n",
    "                                 activation_fn=tf.nn.relu,\n",
    "                                 weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                 biases_initializer=tf.zeros_initializer,\n",
    "                                 normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                 normalizer_params={'scale':True,'scope':'conv_bn5'},\n",
    "                                 scope='conv5')\n",
    "            #print('C_conv5:',conv5.get_shape())\n",
    "            conv6 = tf.contrib.layers.conv2d(conv5,256,\n",
    "                                 kernel_size=3,\n",
    "                                 stride=1,padding='SAME',\n",
    "                                 activation_fn=tf.nn.relu,\n",
    "                                 weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                 biases_initializer=tf.zeros_initializer,\n",
    "                                 normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                 normalizer_params={'scale':True,'scope':'conv_bn6'},\n",
    "                                 scope='conv6')\n",
    "            \n",
    "            #Dilated conv from here\n",
    "            \n",
    "            dilate_conv1 = tf.layers.conv2d(conv6,256,3,strides=1,padding='SAME',dilation_rate=2,\n",
    "                                           kernel_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                           name=\"dilate_conv1\")\n",
    "            dilate_conv1 = tf.contrib.layers.batch_norm(dilate_conv1,scale=True,\n",
    "                                                       scope='dilate_bn1',activation_fn=tf.nn.relu)\n",
    "            \n",
    "            #print('C_dilated_conv1:',dilate_conv1.get_shape())\n",
    "            \n",
    "            dilate_conv2 = tf.layers.conv2d(dilate_conv1,256,3,strides=1,padding='SAME',dilation_rate=4,\n",
    "                                           kernel_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                           name=\"dilate_conv2\")\n",
    "            dilate_conv2 = tf.contrib.layers.batch_norm(dilate_conv2,scale=True,\n",
    "                                                       scope='dilate_bn2',activation_fn=tf.nn.relu)\n",
    "            \n",
    "            #print('C_dilated_conv2:',dilate_conv2.get_shape())\n",
    "            \n",
    "            dilate_conv3 = tf.layers.conv2d(dilate_conv2,256,3,strides=1,padding='SAME',dilation_rate=8,\n",
    "                                           kernel_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                           name=\"dilate_conv3\")\n",
    "            dilate_conv3 = tf.contrib.layers.batch_norm(dilate_conv3,scale=True,\n",
    "                                                       scope='dilate_bn3',activation_fn=tf.nn.relu)\n",
    "            \n",
    "            #print('C_dilated_conv3:',dilate_conv3.get_shape())\n",
    "            \n",
    "            dilate_conv4 = tf.layers.conv2d(dilate_conv3,256,3,strides=1,padding='SAME',dilation_rate=16,\n",
    "                                           kernel_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                           name=\"dilate_conv4\")\n",
    "            dilate_conv4 = tf.contrib.layers.batch_norm(dilate_conv3,scale=True,\n",
    "                                                       scope='dilate_bn4',activation_fn=tf.nn.relu)\n",
    "            \n",
    "            #print('C_dilated_conv4:',dilate_conv4.get_shape())\n",
    "\n",
    "            #resize back\n",
    "            \n",
    "            conv7 = tf.contrib.layers.conv2d(dilate_conv4,256,\n",
    "                                 kernel_size=3,\n",
    "                                 stride=1,padding='SAME',\n",
    "                                 activation_fn=tf.nn.relu,\n",
    "                                 weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                 biases_initializer=tf.zeros_initializer,\n",
    "                                 normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                 normalizer_params={'scale':True,'scope':'conv_bn7'},\n",
    "                                 scope='conv7')\n",
    "            \n",
    "            #print('C_conv7:',conv7.get_shape())\n",
    "            conv8 = tf.contrib.layers.conv2d(conv7,256,\n",
    "                                 kernel_size=3,\n",
    "                                 stride=1,padding='SAME',\n",
    "                                 activation_fn=tf.nn.relu,\n",
    "                                 weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                 biases_initializer=tf.zeros_initializer,\n",
    "                                 normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                 normalizer_params={'scale':True,'scope':'conv_bn8'},\n",
    "                                 scope='conv8')\n",
    "            #print('C_conv8:',conv8.get_shape())\n",
    "            deconv1 = tf.layers.conv2d_transpose(conv8,128,4,strides=2,\n",
    "                                                    padding=\"SAME\",\n",
    "                                                    use_bias=False,\n",
    "                                                    name=\"deconv1\",\n",
    "                                                    kernel_initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "            tf.contrib.layers.batch_norm(deconv1,scale=True,scope='deconv_bn1',activation_fn=tf.nn.relu)\n",
    "            \n",
    "            #print('C_deconv1:',deconv1.get_shape())\n",
    "            \n",
    "            conv9 = tf.contrib.layers.conv2d(deconv1,128,\n",
    "                                 kernel_size=3,\n",
    "                                 stride=1,padding='SAME',\n",
    "                                 activation_fn=tf.nn.relu,\n",
    "                                 weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                 biases_initializer=tf.zeros_initializer,\n",
    "                                 normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                 normalizer_params={'scale':True,'scope':'conv_bn9'},\n",
    "                                 scope='conv9')\n",
    "\n",
    "            #print('C_conv9:',conv9.get_shape())\n",
    "            \n",
    "            deconv2 = tf.layers.conv2d_transpose(conv9,64,4,strides=2,\n",
    "                                                    padding=\"SAME\",\n",
    "                                                    use_bias=False,\n",
    "                                                    name=\"deconv2\",\n",
    "                                                    kernel_initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "            tf.contrib.layers.batch_norm(deconv2,scale=True,scope='deconv_bn2',activation_fn=tf.nn.relu)\n",
    "            \n",
    "            #print('C_deconv2:',deconv2.get_shape())\n",
    "            conv10 = tf.contrib.layers.conv2d(deconv2,32,\n",
    "                                 kernel_size=3,\n",
    "                                 stride=1,padding='SAME',\n",
    "                                 activation_fn=tf.nn.relu,\n",
    "                                 weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                 biases_initializer=tf.zeros_initializer,\n",
    "                                 normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                 normalizer_params={'scale':True,'scope':'conv_bn10'},\n",
    "                                 scope='conv10')\n",
    "            \n",
    "            #print('C_conv10:',conv10.get_shape())\n",
    "            conv11 = tf.contrib.layers.conv2d(conv10,3,\n",
    "                                 kernel_size=3,\n",
    "                                 stride=1,padding='SAME',\n",
    "                                 activation_fn=tf.nn.sigmoid,\n",
    "                                 weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                 biases_initializer=tf.zeros_initializer,\n",
    "                                 scope='conv11')\n",
    "            #print('C_conv11:',conv11.get_shape())   \n",
    "            return conv11, nets\n",
    "\n",
    "    # D network from DCGAN\n",
    "    def local_discriminator(self, input, name=\"local_discriminator\", reuse=False):\n",
    "        nets = []\n",
    "        with tf.variable_scope(name, reuse=reuse) as scope:\n",
    "            \n",
    "            #print('L_input:',input.get_shape())\n",
    "            conv1 = tf.contrib.layers.conv2d(input, 64, 5, 2,\n",
    "                                             padding=\"SAME\",\n",
    "                                             activation_fn=tf.nn.relu,\n",
    "                                             weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                             biases_initializer=tf.zeros_initializer,\n",
    "                                             normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                             normalizer_params={'scale':True,'scope':'bn1'},\n",
    "                                             scope='conv1')\n",
    "            nets.append(conv1)\n",
    "            #print('L_conv1:',conv1.get_shape())\n",
    "            conv2 = tf.contrib.layers.conv2d(conv1, 128, 5, 2,\n",
    "                                             padding='SAME',\n",
    "                                             activation_fn=tf.nn.relu,\n",
    "                                             weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                             biases_initializer=tf.zeros_initializer,\n",
    "                                             normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                             normalizer_params={'scale':True,'scope':'bn2'},\n",
    "                                             scope='conv2')\n",
    "            nets.append(conv2)\n",
    "            #print('L_conv2:',conv2.get_shape())\n",
    "            conv3 = tf.contrib.layers.conv2d(conv2, 256, 5, 2,\n",
    "                                             padding='SAME',\n",
    "                                             activation_fn=tf.nn.relu,\n",
    "                                             weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                             biases_initializer=tf.zeros_initializer,\n",
    "                                             normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                             normalizer_params={'scale':True,'scope':'bn3'},\n",
    "                                             scope='conv3')\n",
    "            nets.append(conv3)\n",
    "            #print('L_conv3:',conv3.get_shape())\n",
    "            conv4 = tf.contrib.layers.conv2d(conv3, 512, 5, 2,\n",
    "                                             padding='SAME',\n",
    "                                             activation_fn=tf.nn.relu,\n",
    "                                             weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                             biases_initializer=tf.zeros_initializer,\n",
    "                                             normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                             normalizer_params={'scale':True,'scope':'bn4'},\n",
    "                                             scope='conv4')\n",
    "            nets.append(conv4)\n",
    "\n",
    "            #print('L_conv4:',conv4.get_shape())\n",
    "\n",
    "            flatten = tf.contrib.layers.flatten(conv4)\n",
    "            \n",
    "            output = tf.contrib.layers.fully_connected(flatten,1024,\n",
    "                                                       activation_fn=tf.nn.relu,\n",
    "                                                       scope='L_linear')\n",
    "\n",
    "            return output, nets\n",
    "\n",
    "\n",
    "\n",
    "    def global_discriminator(self, input, name=\"global_discriminator\", reuse=False):\n",
    "        nets = []\n",
    "        with tf.variable_scope(name, reuse=reuse) as scope:\n",
    "            #print('G_input:',input.get_shape())\n",
    "            conv1 = tf.contrib.layers.conv2d(input, 64, 5, 2,\n",
    "                                     padding=\"SAME\",\n",
    "                                     activation_fn=tf.nn.relu,\n",
    "                                     weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                     biases_initializer=tf.zeros_initializer,\n",
    "                                     normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                     normalizer_params={'scale':True,'scope':'bn1'},\n",
    "                                     scope='conv1')\n",
    "            nets.append(conv1)\n",
    "            #print('G_conv1:',conv1.get_shape())\n",
    "\n",
    "            conv2 = tf.contrib.layers.conv2d(conv1, 128, 5, 2,\n",
    "                                     padding=\"SAME\",\n",
    "                                     activation_fn=tf.nn.relu,\n",
    "                                     weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                     biases_initializer=tf.zeros_initializer,\n",
    "                                     normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                     normalizer_params={'scale':True,'scope':'bn2'},\n",
    "                                     scope='conv2')\n",
    "            nets.append(conv2)\n",
    "            #print('G_conv2:',conv2.get_shape())\n",
    "\n",
    "            conv3 = tf.contrib.layers.conv2d(conv2, 256, 5, 2,\n",
    "                                     padding=\"SAME\",\n",
    "                                     activation_fn=tf.nn.relu,\n",
    "                                     weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                     biases_initializer=tf.zeros_initializer,\n",
    "                                     normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                     normalizer_params={'scale':True,'scope':'bn3'},\n",
    "                                     scope='conv3')\n",
    "        \n",
    "            nets.append(conv3)\n",
    "            #print('G_conv3:',conv3.get_shape())\n",
    "\n",
    "            conv4 = tf.contrib.layers.conv2d(conv3, 512, 5, 2,\n",
    "                                             padding=\"SAME\",\n",
    "                                             activation_fn=tf.nn.relu,\n",
    "                                             weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                             biases_initializer=tf.zeros_initializer,\n",
    "                                             normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                             normalizer_params={'scale':True,'scope':'bn4'},\n",
    "                                             scope='conv4')\n",
    "      \n",
    "            nets.append(conv4)\n",
    "            #print('G_conv4:',conv4.get_shape())\n",
    "\n",
    "            conv5 = tf.contrib.layers.conv2d(conv4, 512, 5, 2,\n",
    "                                             padding=\"SAME\",\n",
    "                                             activation_fn=tf.nn.relu,\n",
    "                                             weights_initializer=tf.random_normal_initializer(stddev=0.02),\n",
    "                                             biases_initializer=tf.zeros_initializer,\n",
    "                                             normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                             normalizer_params={'scale':True,'scope':'bn5'},\n",
    "                                             scope='conv5')\n",
    "            \n",
    "            nets.append(conv5)\n",
    "            #print('G_conv5:',conv5.get_shape())\n",
    "\n",
    "            flatten = tf.contrib.layers.flatten(conv5)\n",
    "            \n",
    "            output = tf.contrib.layers.fully_connected(flatten,1024,\n",
    "                                                       activation_fn=tf.nn.relu,\n",
    "                                                       scope='G_linear')\n",
    "\n",
    "            return output, nets\n",
    "\n",
    "def train(args, sess, model):\n",
    "    # Adam optimizers are used instead of AdaDelta\n",
    "    # Use var_list to restrict the gradient\n",
    "    d_optimizer = tf.train.AdamOptimizer(args.learning_rate, beta1=args.momentum, name=\"AdamOptimizer_D\").minimize(model.d_loss, var_list=model.d_vars)\n",
    "    c_optimizer = tf.train.AdamOptimizer(args.learning_rate, beta1=args.momentum, name=\"AdamOptimizer_C\").minimize(model.recon_loss, var_list=model.c_vars)\n",
    "    global_optimizer = tf.train.AdamOptimizer(args.learning_rate, beta1=args.momentum, name=\"AdamOptimizer_C\").minimize(model.loss_all, var_list=model.c_vars)\n",
    "\n",
    "    epoch = 0\n",
    "    step = 1\n",
    "    global_step = 0\n",
    "\n",
    "    saver = tf.train.Saver()        \n",
    "    if args.continue_training:\n",
    "        tf.local_variables_initializer().run()\n",
    "        last_ckpt = tf.train.latest_checkpoint(args.checkpoints_path)\n",
    "        saver.restore(sess, last_ckpt)\n",
    "        ckpt_name = str(last_ckpt)\n",
    "        print (\"Loaded model file from \" + ckpt_name)\n",
    "        step = int(ckpt_name.split('-')[-1])\n",
    "    else:\n",
    "        tf.global_variables_initializer().run()\n",
    "        tf.local_variables_initializer().run()\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "    #summary init\n",
    "    all_summary = tf.summary.merge([model.recon_loss_sum,\n",
    "                                    model.d_loss_sum,\n",
    "                                    model.loss_all_sum,\n",
    "                                    model.input_img_sum, \n",
    "                                    model.real_img_sum,\n",
    "                                    model.recon_img_sum,\n",
    "                                    model.g_local_imgs_sum,\n",
    "                                    model.r_local_imgs_sum])\n",
    "    writer = tf.summary.FileWriter(args.graph_path, sess.graph)\n",
    "\n",
    "    # Training strating point\n",
    "    while step < args.train_step:\n",
    "\n",
    "        #Training Stage 1 (Completion Network)\n",
    "        if step < args.Tc:\n",
    "            # the main training step is the optimizer <only optimizing classify>\n",
    "            # Treat it as a decoder\n",
    "            summary, c_loss, _ = sess.run([all_summary, model.recon_loss, c_optimizer])\n",
    "            writer.add_summary(summary, step)\n",
    "            print (\"Epoch [%d] | Step [%d] | C Loss: [%.4f]\" % (epoch, step, c_loss))\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            #Training Stage 2 (Discriminator Network)\n",
    "            summary, d_loss, _ = sess.run([all_summary, model.d_loss, d_optimizer])\n",
    "            writer.add_summary(summary, step)\n",
    "            print (\"Epoch [%d] | Step [%d] | D Loss: [%.4f]\" % (epoch, step, d_loss))\n",
    "            \n",
    "            if step > args.Tc + args.Td:\n",
    "                #Training Stage 3 (Completion Network)\n",
    "                summary, g_loss, _ = sess.run([all_summary, model.loss_all, global_optimizer])\n",
    "                writer.add_summary(summary, global_step)\n",
    "                print (\"Epoch [%d] | Step [%d] | G Loss: [%.4f]\" % (epoch, step, g_loss))\n",
    "        \n",
    "        # Show the training image\n",
    "        if step % args.show_freq ==0:            \n",
    "            fig = plt.figure()\n",
    "            fig.add_subplot(1,2,1)\n",
    "            plt.imshow(np.asarray(sess.run(model.recon_img)[0]))\n",
    "            plt.show()\n",
    "\n",
    "        # Check Test image results every time epoch is finished\n",
    "        if step*args.batch_size >= model.data_count:\n",
    "            saver.save(sess, args.checkpoints_path + \"/model\",global_step=step)\n",
    "            \n",
    "        step += 1\n",
    "        \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    sess.close()            \n",
    "    print(\"Done.\")\n",
    "\n",
    "    \n",
    "# Testing Variables\n",
    "drawing = False \n",
    "ix,iy = -1,-1\n",
    "color = (255,255,255)\n",
    "size = 10    \n",
    "       \n",
    "def erase_img(args, img):\n",
    "\n",
    "    # mouse callback function\n",
    "    def erase_rect(event,x,y,flags,param):\n",
    "        global ix,iy,drawing\n",
    "\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            drawing = True\n",
    "            if drawing == True:\n",
    "                # cv2.circle(img,(x,y),10,(255,255,255),-1)\n",
    "                cv2.rectangle(img,(x-size,y-size),(x+size,y+size),color,-1)\n",
    "                cv2.rectangle(mask,(x-size,y-size),(x+size,y+size),color,-1)\n",
    "            \n",
    "        elif event == cv2.EVENT_MOUSEMOVE:\n",
    "            if drawing == True:\n",
    "                # cv2.circle(img,(x,y),10,(255,255,255),-1)\n",
    "                cv2.rectangle(img,(x-size,y-size),(x+size,y+size),color,-1)\n",
    "                cv2.rectangle(mask,(x-size,y-size),(x+size,y+size),color,-1)\n",
    "        elif event == cv2.EVENT_LBUTTONUP:\n",
    "            drawing = False\n",
    "            # cv2.circle(img,(x,y),10,(255,255,255),-1)\n",
    "            cv2.rectangle(img,(x-size,y-size),(x+size,y+size),color,-1)\n",
    "            cv2.rectangle(mask,(x-size,y-size),(x+size,y+size),color,-1)\n",
    "\n",
    "\n",
    "    cv2.namedWindow('image')\n",
    "    cv2.setMouseCallback('image',erase_rect)\n",
    "    #cv2.namedWindow('mask')\n",
    "    cv2.setMouseCallback('mask',erase_rect)\n",
    "    mask = np.zeros(img.shape)\n",
    "    \n",
    "\n",
    "    while(1):\n",
    "        img_show = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        cv2.imshow('image',img_show)\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "        if k == 10:\n",
    "            break\n",
    "            \n",
    "    test_img = cv2.resize(img, (args.input_height, args.input_width))/255.0\n",
    "    test_mask = cv2.resize(mask, (args.input_height, args.input_width))/255.0\n",
    "    #fill mask region to 1\n",
    "    test_img = (test_img * (1-test_mask)) + test_mask\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    return np.tile(test_img[np.newaxis,:], [args.batch_size,1,1,1]), np.tile(test_mask[np.newaxis,:], [args.batch_size,1,1,1])\n",
    "\n",
    "\n",
    "def test(args, sess, model):\n",
    "    #saver  \n",
    "    saver = tf.train.Saver()        \n",
    "    last_ckpt = tf.train.latest_checkpoint(args.checkpoints_path)\n",
    "    saver.restore(sess, last_ckpt)\n",
    "    ckpt_name = str(last_ckpt)\n",
    "    print (\"Loaded model file from \" + ckpt_name)\n",
    "    \n",
    "    img = cv2.imread(args.img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    orig_test = cv2.resize(img, (args.input_height, args.input_width))/127.5 - 1\n",
    "    orig_test = np.tile(orig_test[np.newaxis,:],[args.batch_size,1,1,1])\n",
    "    orig_test = orig_test.astype(np.float32)\n",
    "\n",
    "    orig_w, orig_h = img.shape[0], img.shape[1]\n",
    "    test_img, mask = erase_img(args, img)\n",
    "    test_img = test_img.astype(np.float32)\n",
    "    \n",
    "    print (\"Testing ...\")\n",
    "    res_img = sess.run(model.test_res_imgs, feed_dict={model.single_orig:orig_test,\n",
    "                                                       model.single_test:test_img,\n",
    "                                                       model.single_mask:mask})\n",
    "\n",
    "    orig = cv2.resize((orig_test[0]+1)//2, (orig_h//2, orig_w//2))\n",
    "    test = cv2.resize((test_img[0]+1)//2, (orig_h//2, orig_w//2))\n",
    "    recon = cv2.resize((res_img[0]+1)//2, (orig_h//2, orig_w//2))\n",
    "\n",
    "    res = np.hstack([orig,test,recon])\n",
    "    res = cv2.cvtColor(res, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    cv2.imshow(\"result\", res)\n",
    "    cv2.waitKey()\n",
    "\n",
    "    print(\"Done.\")\n",
    "\n",
    "    \n",
    "def main_test(_):\n",
    "    run_config = tf.ConfigProto()\n",
    "    run_config.gpu_options.allow_growth = True\n",
    "    \n",
    "    with tf.Session(config=run_config) as sess:\n",
    "        model = network(args)\n",
    "\n",
    "        print ('Start Testing...')\n",
    "        test(args, sess, model)    \n",
    "    \n",
    "    \n",
    "def main_train(_):\n",
    "    run_config = tf.ConfigProto()\n",
    "    run_config.gpu_options.allow_growth = True\n",
    "\n",
    "    # Setting folders\n",
    "    if not os.path.exists(args.checkpoints_path):\n",
    "        os.makedirs(args.checkpoints_path)\n",
    "    if not os.path.exists(args.graph_path):\n",
    "        os.makedirs(args.graph_path)\n",
    "    if not os.path.exists(args.images_path):\n",
    "        os.makedirs(args.images_path)\n",
    "        \n",
    "    with tf.Session(config=run_config) as sess:\n",
    "        model = network(args)\n",
    "        print ('Start Training...')\n",
    "        train(args, sess, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "args= Parser()        \n",
    "tf.reset_default_graph()\n",
    "main_train(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing (Need model)\n",
    "\n",
    "#tf.reset_default_graph()\n",
    "#main_test(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
